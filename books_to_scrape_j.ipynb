{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce88e06a",
   "metadata": {},
   "source": [
    "# Books Online Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccf0fa",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e241eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv, re, os, shutil, time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0a404",
   "metadata": {},
   "source": [
    "## Starting Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861caf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481e8ac",
   "metadata": {},
   "source": [
    "### Setting Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76f986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Working Directory\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "base_folder = current_folder + '/' + 'Categories'\n",
    "os.chdir(base_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d86a75",
   "metadata": {},
   "source": [
    "### Creating Functions that will be used in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d442947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Soup\n",
    "def build_soup(url):    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Title\n",
    "def get_title(soup):\n",
    "    product_main =soup.find(class_=\"col-sm-6 product_main\")\n",
    "    title = product_main.h1.string\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a68ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Description\n",
    "def get_description(soup):\n",
    "    description = soup.find('meta', attrs={\"name\": \"description\"}).get('content')\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ad3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing table that contains multiple data points. \n",
    "# [0] universal_product_code\n",
    "# [2] price_excluding_tax\n",
    "# [3] price_excluding_tax\n",
    "# [5] number_available\n",
    "\n",
    "def get_table(soup):\n",
    "    data = []\n",
    "    table = soup.find('table', class_='table-striped')\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        for element in row.find_all('td'):\n",
    "            data.append(element.string)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84be7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal_product_code\n",
    "def get_upc(data):\n",
    "    universal_product_code = data[0]\n",
    "    return universal_product_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff174f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_excluding_tax\n",
    "def get_price_excluding_tax(data):\n",
    "    price_excluding_tax = data[2]\n",
    "    return price_excluding_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a079b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_including_tax\n",
    "def get_price_including_tax(data):\n",
    "    price_including_tax = data[3]\n",
    "    return price_including_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ee54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_available\n",
    "def get_number_available(data):\n",
    "    number_available = data[5]\n",
    "    return number_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5221a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category\n",
    "def get_category(soup):\n",
    "    category = cat_name\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e1b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review rating\n",
    "def get_review_rating(soup):\n",
    "    review_rating = str(soup.find(\"p\", class_=\"star-rating\"))\n",
    "    temp_list = review_rating.split(' ')\n",
    "    rating = temp_list[2]\n",
    "    stars = rating[:-5]\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805cccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image URL\n",
    "def get_image_url(soup):\n",
    "    url_list = soup.find_all(\"img\")\n",
    "    image_url = re.sub(\"\\../../\",\"https://books.toscrape.com/\", url_list[0]['src'])\n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f525afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function aggregates the function above, together they create a row to add to the CSV file with a single book's data\n",
    "\n",
    "def get_row(url):\n",
    "    soup                   = build_soup(url)\n",
    "    title                  = get_title(soup)\n",
    "    description            = get_description(soup)\n",
    "    data                   = get_table(soup)\n",
    "    universal_product_code = get_upc(data)\n",
    "    price_excluding_tax    = get_price_excluding_tax(data)\n",
    "    price_including_tax    = get_price_including_tax(data)\n",
    "    number_available       = get_number_available(data)\n",
    "    category               = get_category(soup)\n",
    "    review_rating          = get_review_rating(soup)\n",
    "    image_url              = get_image_url(soup)\n",
    "    data_row =[title, description, universal_product_code, price_excluding_tax, price_including_tax, number_available, category, review_rating, image_url]\n",
    "    return data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63d8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Dowload\n",
    "def download_image(url,name):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    r = requests.get(url, stream = True)\n",
    "    if r.status_code == 200:\n",
    "        r.raw.decode_content = True\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b2ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_sub_function(category):\n",
    "\n",
    "    #Creating list of urls for the category\n",
    "    category_sub_list = []\n",
    "    category_sub_list.append(category)\n",
    "    \n",
    "    # Building the soup \n",
    "    soup = build_soup(category)\n",
    "    has_next = soup.find(class_=\"next\")\n",
    "\n",
    "    i=1\n",
    "    while has_next != None:\n",
    "        has_next_str = str(has_next)\n",
    "        temp_list = has_next_str.split(' ')\n",
    "        next_page=temp_list[2]\n",
    "        next_name = re.findall('page.*html', next_page)[0]\n",
    "        category_sub_list.append(re.sub(\"index.html\",next_name, category))\n",
    "        soup = build_soup(category_sub_list[i])\n",
    "        has_next = soup.find(class_=\"next\")\n",
    "        i = i + 1 \n",
    "    return(category_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8fbc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial list of book URLs\n",
    "def make_url_list(category):\n",
    "    # Build the Soup for the Category\n",
    "    book_soup = build_soup(category)\n",
    "    \n",
    "    # Find all Books URLs. URLs are relative paths, which will need to be subsituted\n",
    "    book_container = book_soup.find_all('article',{'class': \"product_pod\"})\n",
    "    book_url_list.clear()\n",
    "    for article in book_container:\n",
    "        for tag in article.find_all('a',{'href': True}, limit=1):\n",
    "            book_url_list.append(tag['href'])\n",
    "\n",
    "    # Creating new list with absolute path URLs\n",
    "    for book in book_url_list:\n",
    "        absolute_book_url_list.append(re.sub(\"\\../../../\",\"https://books.toscrape.com/catalogue/\", book))\n",
    "    return(absolute_book_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497d5c0",
   "metadata": {},
   "source": [
    "## Making a list of Category URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795310d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The block below will create the list of URLs for each Category\n",
    "\n",
    "#Making the soup for the main page\n",
    "main_page = \"http://books.toscrape.com/catalogue/category/books_1/index.html\"\n",
    "main_soup = build_soup(main_page)\n",
    "container = main_soup.find(class_=\"side_categories\")\n",
    "\n",
    "#Creating list called \"url_list\" with Soup object\n",
    "url_list=[]\n",
    "for tag in container.find_all('a',{'href': True}):\n",
    "    url_list.append(tag['href'])\n",
    "    \n",
    "# Creating list that contains strings from url_list and adds missing part of https address\n",
    "full_category_list=[]\n",
    "for category in url_list:\n",
    "    # Creating a full url\n",
    "    full_category_list.append(re.sub(\"\\../\",\"https://books.toscrape.com/catalogue/category/\", category))\n",
    "del full_category_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad0375",
   "metadata": {},
   "source": [
    "## Looping Through Books and Categories and Writting in CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c9468ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel_2.csv\n",
      "mystery_3.csv\n",
      "historical-fiction_4.csv\n",
      "sequential-art_5.csv\n",
      "classics_6.csv\n",
      "philosophy_7.csv\n",
      "romance_8.csv\n",
      "womens-fiction_9.csv\n",
      "fiction_10.csv\n",
      "childrens_11.csv\n",
      "religion_12.csv\n",
      "nonfiction_13.csv\n",
      "music_14.csv\n",
      "default_15.csv\n",
      "science-fiction_16.csv\n",
      "sports-and-games_17.csv\n",
      "add-a-comment_18.csv\n",
      "fantasy_19.csv\n",
      "new-adult_20.csv\n",
      "young-adult_21.csv\n",
      "science_22.csv\n",
      "poetry_23.csv\n",
      "paranormal_24.csv\n",
      "art_25.csv\n",
      "psychology_26.csv\n",
      "autobiography_27.csv\n",
      "parenting_28.csv\n",
      "adult-fiction_29.csv\n",
      "humor_30.csv\n",
      "horror_31.csv\n",
      "history_32.csv\n",
      "food-and-drink_33.csv\n",
      "christian-fiction_34.csv\n",
      "business_35.csv\n",
      "biography_36.csv\n",
      "thriller_37.csv\n",
      "contemporary_38.csv\n",
      "spirituality_39.csv\n",
      "academic_40.csv\n",
      "self-help_41.csv\n",
      "historical_42.csv\n",
      "christian_43.csv\n",
      "suspense_44.csv\n",
      "short-stories_45.csv\n",
      "novels_46.csv\n",
      "health_47.csv\n",
      "politics_48.csv\n",
      "cultural_49.csv\n",
      "erotica_50.csv\n",
      "crime_51.csv\n"
     ]
    }
   ],
   "source": [
    "# This is incomplete pending \"If Then\" for multipage categories\n",
    "\n",
    "book_url_list=[]\n",
    "# Start with the category list\n",
    "for category in full_category_list:\n",
    "    # Create a Name for the csv file and change working directory\n",
    "    folder_name = re.search('books/(.+?)/index.html', category).group(1)\n",
    "    \n",
    "    # Changing Working Directory\n",
    "    os.chdir(base_folder)\n",
    "    path_name = base_folder + '/' + folder_name\n",
    "    if os.path.exists(path_name):  \n",
    "        os.chdir(path_name)\n",
    "    else:\n",
    "        os.mkdir(path_name)\n",
    "        os.chdir(path_name)\n",
    "    \n",
    "    # Clear the book url list\n",
    "    absolute_book_url_list =  []\n",
    "    cat_list = category_sub_function(category)\n",
    "    for cat in cat_list:\n",
    "        absolute_book_url_list = make_url_list(cat)\n",
    "    \n",
    "    # Build CSV file name\n",
    "    cat_name = re.search('books/(.+?)/index.html', category).group(1)\n",
    "    category_name = re.search('books/(.+?)/index.html', category).group(1) + \".csv\"\n",
    "    \n",
    "    header = ['title','description','universal_product_code', 'price_excluding_tax', 'price_including_tax', 'number_available', 'category', 'review_rating', 'image_url']\n",
    "    with open(category_name, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(header)\n",
    "        for x in absolute_book_url_list:\n",
    "            url = x\n",
    "            data_row = get_row(url)\n",
    "            writer.writerow(data_row)\n",
    "            \n",
    "            #Download Image\n",
    "            download_image(data_row[8],data_row[0])\n",
    "    \n",
    "    # Print the name of each CSV file as writting it is completed. \n",
    "    print(category_name)\n",
    "os.chdir(base_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b295812",
   "metadata": {},
   "source": [
    "## Stopping Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeed606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.1\n"
     ]
    }
   ],
   "source": [
    "toc = time.perf_counter()\n",
    "\n",
    "print(round((toc-tic)/60,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305609d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
